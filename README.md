# XTTS V2 Voice Cloning - Universal GPU Support

## ğŸ“‹ What is this?

Professional voice cloning script using Coqui XTTS V2, with **universal GPU acceleration** (NVIDIA, AMD, Apple Silicon) and advanced features that make it superior to using raw XTTS V2.

## âœ¨ Why use this script instead of raw Coqui XTTS V2?

### ğŸ¯ Advanced Features Not Available in Standard XTTS V2:

1. **Intelligent Linguistic Segmentation**
   - Automatically splits text at natural punctuation points (`.`, `?`, `!`, `;`, `:`, `,`)
   - Respects sentence boundaries for natural speech flow
   - Prevents memory errors on long texts (15+ minute audio)

2. **Automatic Voice Calibration** 
   - Analyzes your voice with advanced algorithms (YIN pitch detection, spectral analysis, MFCC)
   - Auto-optimizes TTS parameters for maximum fidelity
   - No manual parameter tuning needed

3. **Sentiment-Aware Processing**
   - Detects emotions in text (joy, anger, sadness, surprise, fear, neutral)
   - Adjusts intonation and expressiveness automatically
   - Natural-sounding emotional delivery

4. **Linking Word Optimization**
   - Intelligent handling of conjunctions and transitions ("and", "but", "however", "therefore")
   - Preserves natural speech rhythm and flow
   - Prevents robotic-sounding pauses

5. **Universal GPU Acceleration**
   - **NVIDIA GPUs**: CUDA acceleration (3-5x faster than CPU)
   - **AMD GPUs**: ROCm support (3-5x faster than CPU)
   - **Apple Silicon**: Native MPS acceleration (3-5x faster than CPU)
   - Automatic GPU detection and optimal device selection

6. **Multi-Language Support**
   - Native support for **17 languages** (English, Spanish, French, German, Italian, Portuguese, Polish, Turkish, Russian, Dutch, Czech, Arabic, Chinese, Japanese, Hungarian, Korean, Hindi)
   - Simple language selection via `--language` parameter
   - Default: English (no parameter needed)

7. **Professional Audio Processing**
   - Native WAV concatenation without quality loss
   - Automatic segment blending for seamless output
   - No external dependencies (ffmpeg) needed

**Bottom line**: Raw XTTS V2 = basic TTS. This script = production-ready voice cloning system.

---

## ğŸ–¥ï¸ System Requirements

- **Python**: 3.11 (recommended) - other versions (3.10-3.12) may work but 3.11 is optimal
- **OS**: macOS 14+, Windows 10+, or Linux (Ubuntu 20.04+)
- **RAM**: Minimum 8GB, recommended 16GB
- **Storage**: ~6GB free space (4GB models + 2GB dependencies)
- **GPU** (optional): NVIDIA (CUDA), AMD (ROCm), or Apple Silicon (MPS) - **3-5x faster than CPU**

---

---

## âš ï¸ ğŸ”´ **CRITICAL REQUIREMENT - READ THIS FIRST!** ğŸ”´

> **Before running this script, you MUST have your own voice recording file in the project folder!**
> 
> - **Required file**: `speaker.wav` (or any audio file with your voice)
> - **Location**: Must be in the project directory (`Coqui-XTTS-V2-Enhanced-AppleSilicon-Nvidia-AMD-CPU/`)
> - **Without this file, the script CANNOT clone your voice!**
> 
> ğŸ‘‰ **See the [Speaker.wav Requirements](#ï¸-requirements-for-speakerwav-your-voice-file) section below for recording guidelines.**

---

## ğŸ™ï¸ Requirements for `speaker.wav` (Your Voice File)

### âœ… Critical Requirements for High-Quality Cloning:

1. **Duration**: 10-30 seconds (optimal: 15-20 seconds)
   - Too short (< 10s): Insufficient vocal characteristics
   - Too long (> 30s): Unnecessary and slower processing

2. **Content**: Natural, expressive speech
   - Read 2-3 complete sentences
   - Include varied intonation (not monotone)
   - Speak at normal conversational pace

3. **Audio Quality**:
   - **Format**: WAV, MP3, or FLAC
   - **Sample rate**: 22050 Hz or higher
   - **Bit depth**: 16-bit minimum
   - **Background noise**: Minimal to none (record in quiet room)
   - **Clarity**: No distortion, clipping, or echoes

4. **Recording Tips**:
   - Use a decent microphone (built-in Mac mic is acceptable)
   - Maintain consistent distance from microphone (15-20 cm)
   - Avoid pops and sibilance (use pop filter if available)
   - Record in quiet environment (no fans, traffic, or background voices)
   - Speak naturally - don't shout or whisper

### âš ï¸ What to Avoid:
- âŒ Music or sound effects in background
- âŒ Multiple speakers
- âŒ Heavy compression or audio processing
- âŒ Phone call quality recordings
- âŒ Recordings with echo or reverb

**Example good recording**: "Hello, this is my natural speaking voice. I'm recording this sample for voice cloning purposes. The quality of this recording will determine how accurate the cloned voice sounds."

---

## ğŸ“¦ Installation (5 minutes)

```bash
# 1. Navigate to project folder
cd XTTS_Voice_Cloning

# 2. Create Python virtual environment
python3 -m venv venv

# 3. Activate virtual environment
source venv/bin/activate

# 4. Upgrade pip (important!)
pip install --upgrade pip

# 5. Install dependencies
pip install -r requirements.txt
```

### GPU Setup (Optional - for NVIDIA/AMD users):

**NVIDIA GPU:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**AMD GPU (Linux only):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
```

**Apple Silicon:** No extra setup needed - MPS support is built-in.

**Note**: First run will download XTTS V2 models (~2GB) - this is normal and only happens once.

---

## ğŸš€ Usage

### Basic Command Structure

```bash
# First, activate the virtual environment
source venv/bin/activate

# Basic syntax
python3 generate_audio.py <voice_file> <text_file> -o <output_file>

# Example 1: Using default files (speaker.wav + sample_text_for_clone.txt)
python3 generate_audio.py speaker.wav sample_text_for_clone.txt -o output.wav

# Example 2: Custom files
python3 generate_audio.py my_voice.wav my_script.txt -o tutorial.wav

# Example 3: With speed adjustment
python3 generate_audio.py speaker.wav script.txt --speed 1.1 -o fast_tutorial.wav

# Example 4: All custom parameters
python3 generate_audio.py voice.wav text.txt -o output.wav --speed 1.05 --temperature 0.75
```

---

### Available Arguments:

| Argument | Description | Default | Example |
|----------|-------------|---------|---------|
| `speaker_wav` | Your voice file (positional) | `speaker.wav` | `my_voice.wav` |
| `text_file` | Text to clone (positional) | `sample_text_for_clone.txt` | `script.txt` |
| `-o`, `--output` | Output audio file | `cloned_<text_file>.wav` | `tutorial.wav` |
| `--speed` | Speech speed (0.5-2.0) | Auto-calibrated | `1.1` |
| `--temperature` | Voice variation (0.1-1.0) | Auto-calibrated | `0.75` |
| `--top_p` | Sampling diversity (0.1-1.0) | Auto-calibrated | `0.85` |
| `--repetition_penalty` | Avoid repetition (1.0-5.0) | Auto-calibrated | `2.5` |
| `--top_k` | Vocabulary sampling (1-100) | Auto-calibrated | `50` |
| `--language`, `-l` | Target language | `en` (English) | `es`, `fr`, `de`, etc. |

**ğŸ’¡ Tip**: For most users, no parameters are needed - auto-calibration handles everything!

---

### ğŸŒ Multi-Language Support

XTTS V2 supports **17 languages** natively. By default, the script uses **English** (`en`).

**Supported Languages:**
- ğŸ‡¬ğŸ‡§ `en` - English (default)
- ğŸ‡ªğŸ‡¸ `es` - Spanish
- ğŸ‡«ğŸ‡· `fr` - French
- ğŸ‡©ğŸ‡ª `de` - German
- ğŸ‡®ğŸ‡¹ `it` - Italian
- ğŸ‡µğŸ‡¹ `pt` - Portuguese
- ğŸ‡µğŸ‡± `pl` - Polish
- ğŸ‡¹ğŸ‡· `tr` - Turkish
- ğŸ‡·ğŸ‡º `ru` - Russian
- ğŸ‡³ğŸ‡± `nl` - Dutch
- ğŸ‡¨ğŸ‡¿ `cs` - Czech
- ï¿½ï¿½ `ar` - Arabic
- ğŸ‡¨ğŸ‡³ `zh-cn` - Chinese (Simplified)
- ğŸ‡¯ğŸ‡µ `ja` - Japanese
- ğŸ‡­ğŸ‡º `hu` - Hungarian
- ğŸ‡°ğŸ‡· `ko` - Korean
- ğŸ‡®ğŸ‡³ `hi` - Hindi

**âš ï¸ Important:** 
- Your `speaker.wav` file **must be in the same language** as your target language
- For example: Spanish voice file â†’ Spanish text generation
- English voice file â†’ English text generation only

**Usage:**
```bash
# English (default - no need to specify)
python3 generate_audio.py speaker.wav text.txt -o output.wav

# Spanish
python3 generate_audio.py voz_espanol.wav texto.txt --language es -o salida.wav

# French
python3 generate_audio.py voix_francais.wav texte.txt --language fr -o sortie.wav

# German
python3 generate_audio.py stimme_deutsch.wav text.txt --language de -o ausgabe.wav
```

---

### Complete Command Examples:

```bash
# 1. English (default - most common usage)
python3 generate_audio.py speaker.wav sample_text_for_clone.txt -o cloned_output.wav

# 2. Spanish voice cloning
python3 generate_audio.py voz_espanol.wav texto_espanol.txt --language es -o output_es.wav

# 3. French with custom speed
python3 generate_audio.py voix.wav texte.txt --language fr --speed 1.1 -o sortie.wav

# 4. German tutorial (faster speech)
python3 generate_audio.py stimme.wav tutorial.txt --language de --speed 1.15 -o tutorial_de.wav

# 5. English with manual parameter control (advanced)
python3 generate_audio.py voice.wav text.txt -o custom.wav \
  --speed 1.05 \
  --temperature 0.78 \
  --top_p 0.89 \
  --repetition_penalty 2.7 \
  --top_k 45
```

**âš ï¸ Important**: You must specify both the voice file and text file - there are no defaults!

---

## ğŸ“Š What Happens During Processing?

```
1. ğŸ”  Detecting GPU (NVIDIA/AMD/Apple Silicon) or using CPU
2. ğŸ™ï¸  Loading voice file (speaker.wav)
3. ï¿½  Analyzing vocal characteristics (pitch, timbre, spectral features)
4. âš™ï¸   Auto-calibrating TTS parameters
5. ğŸ“  Loading and cleaning text
6. ğŸ­  Analyzing sentiment and emotions
7. âœ‚ï¸   Intelligent segmentation (respecting sentence boundaries)
8. ğŸµ  Generating audio for each segment
9. ğŸ”—  Concatenating segments seamlessly
10. ğŸ’¾  Saving final audio file
11. âœ…  Done!
```

**Typical processing time**: 
- **With GPU**: 3-5 minutes for 2000-3000 characters
- **CPU only**: 15-20 minutes for 2000-3000 characters

---

## ğŸ› ï¸ Troubleshooting

### "ModuleNotFoundError"
```bash
source venv/bin/activate
pip install -r requirements.txt
```

### GPU Not Detected

**Check GPU availability:**
```bash
python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'MPS: {torch.backends.mps.is_available() if hasattr(torch.backends, \"mps\") else False}')"
```

**NVIDIA GPU not detected:**
- Install CUDA-enabled PyTorch: `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121`
- Verify NVIDIA drivers are installed

**AMD GPU not detected (Linux only):**
- Install ROCm-enabled PyTorch: `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7`
- Verify ROCm drivers are installed

**Apple Silicon MPS not detected:**
- Update to macOS 12.3 or later
- Restart terminal after macOS update

**Note:** Script works on CPU if no GPU is detected - just slower (3-5x).

### First run very slow
Normal - downloading XTTS V2 models (~2GB). Subsequent runs are much faster.

### Poor voice quality
1. Check `speaker.wav` quality (see requirements above)
2. Ensure 15-20 second duration
3. Verify quiet recording environment
4. Try re-recording with better microphone

### Script crashes on long text
Should not happen - intelligent segmentation prevents this. If it does, report the issue.

---

## ğŸ“ Project Files

```
XTTS_Voice_Cloning/
â”œâ”€â”€ generate_audio.py              # Main script (universal GPU support)
â”œâ”€â”€ universal_voice_calibrator.py  # Auto-calibration system
â”œâ”€â”€ voice_analyzer.py              # Voice analysis module
â”œâ”€â”€ speaker.wav                    # Your reference voice (replace this!)
â”œâ”€â”€ sample_text_for_clone.txt      # Example text
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ venv/                          # Virtual environment (created during install)
```

---

## ğŸ’¡ Tips for Best Results

1. **Voice Recording**: 
   - Record multiple samples, choose the best one
   - Natural, conversational tone works best
   - Include varied intonation (not monotone)

2. **Text Preparation**:
   - Use proper punctuation for natural pauses
   - Break very long sentences with commas
   - Avoid excessive capitalization or special characters

3. **Speed Settings**:
   - Default (auto-calibrated): Most natural
   - `--speed 1.05-1.1`: Good for tutorials/presentations
   - `--speed 1.15-1.2`: Fast-paced content
   - `--speed 0.9-0.95`: Slower, more deliberate

4. **For YouTube Tutorials**:
   - Use `--speed 1.08` for natural but efficient pacing
   - Record speaker.wav in same environment as final use
   - Keep text well-punctuated for natural pauses

---

## ğŸ†˜ Support

For issues or questions:
1. Check Python version: `python3 --version` (should be 3.11.x)
2. Verify virtual environment is activated: `which python3` (should show venv path)
3. Ensure all dependencies installed: `pip list | grep -i tts`
4. Check GPU detection: See troubleshooting section above

---

## ğŸ“ License

Educational voice cloning system. Ensure you have rights to clone any voice you use.

---

**Version**: 3.0 (Universal GPU Support)  
**Last Updated**: November 18, 2025  
**GPU Support**: NVIDIA CUDA, AMD ROCm, Apple Silicon MPS, CPU fallback

